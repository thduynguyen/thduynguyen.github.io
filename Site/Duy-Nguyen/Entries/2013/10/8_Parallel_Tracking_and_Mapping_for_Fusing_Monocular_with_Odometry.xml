<?xml version="1.0"?>
<content collectionGUID="06D1E943-02B6-4F3B-9555-E9240BE9BD1D">
  <lastEdited clientType="local-build-20140620" date="2014-06-20 16:50:54 +0000"/>
  <textBox id="generic-header-attribute" dynamic="no" visible="yes">
    <richText>&lt;b&gt;Projects&lt;/b&gt;</richText>
  </textBox>
  <textBox id="generic-title-attributes" dynamic="no" visible="yes">
    <richText>Monocular Parallel Tracking and Mapping with Odometry Fusion</richText>
  </textBox>
  <textBox id="generic-body-attributes" dynamic="no" visible="yes">
    <richText>&lt;b&gt;&lt;i&gt;UPDATE 2014-04&lt;/i&gt;&lt;/b&gt;&lt;b&gt;:&lt;/b&gt;&lt;b&gt; &lt;/b&gt;Our &lt;a href="http://www.sciencedirect.com/science/article/pii/S0921889014000542"&gt;RAS journal paper&lt;/a&gt; combining this Parallel framework, &lt;a href="perma://BLPageReference/86D706F7-EE66-4673-8D24-51C912E59022"&gt;Wall-Floor Features&lt;/a&gt; and &lt;a href="perma://BLPageReference/2AF608B8-A5A1-458C-AEC3-60C574853B76"&gt;Vistas&lt;/a&gt; for autonomous indoor navigation has been accepted for publication!&#xD;&#xD;This is my attempt to improve autonomous indoor flight. Our current framework with &lt;a href="perma://BLPageReference/86D706F7-EE66-4673-8D24-51C912E59022"&gt;Wall-Floor Features&lt;/a&gt; and &lt;a href="perma://BLPageReference/2AF608B8-A5A1-458C-AEC3-60C574853B76"&gt;Vistas&lt;/a&gt; is too &#xD;slow for real-time control, so we try to improve its speed with a parallel tracking and mapping framework similar to &lt;a href="http://www.robots.ox.ac.uk/~gk/PTAM/"&gt;PTAM&lt;/a&gt;. The fast tracking thread maintains real-time localization while the slow mapping thread allows high quality wall structure inference. &#xD;&#xD;Unfortunately, although &lt;a href="http://www.robots.ox.ac.uk/~gk/PTAM/"&gt;PTAM&lt;/a&gt; and other pure feature-based monocular SLAM systems are great, they don&#x2019;t work for robots with a single frontal camera in typical indoor environments. The first reason for their failure is that there are not enough corner-type features in the scene, while PTAM typically needs hundreds features to work robustly. The second reason is more important: There are not enough motion parallax to build and maintain a good map, due to the typical robot motions. Since the robot typically moves forward and most features are in front of it, we cannot get reliable depth information. When the robot yaws away from a known map towards unknown regions, PTAM will also break down since it cannot triangulate new landmarks for the map and hence not being able to localize itself.&#xD;&#xD;Thus, we have to fuse monocular PTAM with odometry measurements to cope with the lack of features, and maintain robustness during pure camera rotations. Unfortunately, &lt;a href="http://publications.asl.ethz.ch/files/achtelik11onboard.pdf"&gt;other&lt;/a&gt; PTAM-odometry &lt;a href="http://publications.asl.ethz.ch/files/weiss11real.pdf"&gt;fusion&lt;/a&gt; methods treats PTAM as a black box, so they cannot prevent PTAM&#x2019;s breakdown in these cases. &#xD;&#xD;Using factor graphs, we developed a new parallel tracking and mapping framework that is suitable for robot navigation by fusing visual data with odometry measurements in a principled manner. More details can be found in &lt;a href="http://borg.cc.gatech.edu/papers/335"&gt;our workshop paper&lt;/a&gt;.&#xD;&#xD;&#xD;&lt;b&gt;&#xD;&lt;/b&gt;With this framework, we can finally enable the ARDrone to fly and turn autonomously. This is the first autonomous turn with our parallel framework:&#xD;&#xD;&#xD;&#xD;&#xD;And here is the complete mission towards the end of the hallway. The video stops a bit because our Wifi connection was lost right after the drone turned. I was sitting quite far away and had to run after it to see what happened.&#xD;&#xD;&#xD;&#xD;</richText>
  </textBox>
  <textBox id="generic-datefield-attributes" dynamic="no" visible="yes">
    <richText>&lt;b&gt;Tuesday, October 8, 2013&lt;/b&gt;</richText>
  </textBox>
  <image id="generic-picture-attributes" dynamic="no" visible="yes" src="8_Parallel_Tracking_and_Mapping_for_Fusing_Monocular_with_Odometry_files/shapeimage_2.png" left="0px" top="0px" width="400px" height="300px"/>
</content>
